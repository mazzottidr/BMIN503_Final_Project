---
title: "Sleep complaints in social media"
author: "Diego R. Mazzotti"
date: "11/6/2019"
output: 
  html_document:
    toc: false 
    depth: 3 
    theme: paper 
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Identification of sleep complaints using social media: geographic distribution and effect of changes from daylight savings time to standard time

#### Overview

This study will extract data from Twitter to identify tweets mentioning sleep complaints. We will use the results from a simple machine learning classifier, using manually annotated tweets according to their status of whether the tweet reports a sleep complaint, to classify geotagged tweets posted in the United States. We will then calculate the prevalence of sleep complaints in different geographic regions, including at different latitudes and distances from timezone boundaries to evaluate whether these factors are associated with different prevalance of sleep complaints.

#### Introduction

Sleep disorders affect a large proportion of the population in the United States and worldwide, and it has been associated with several health consequences. Sleep complaints are a manifestation of an acute or chronic state of sleep disturbances and can be captured by a number of validated questionnaires and objective instruments. Social media platforms have been recently considered as another powerful source of data about human behavior. For example, recent studies have explored data generated from Twitter, a micro-blogging social medial platform, and sucesfully captured information about drug exposures, suggesting that it could be a relevant pharmacovigilance tool. Becuase of the importance of good sleep habits for maintenance of health, we hypothesize that sleep-related behaviors, such as sleep complaints, can be captured using social media data mining and natural language processing tools to support digital epidemiology of sleep disorders.

In this study, I will utilize tools that I was exposed during the Data Science for Biomedical Informatics course to design a proof-of-concept study of the ability to capture sleep-complaints from Twitter data. In collaboration with other faculty members at the University of Pennsylvania (Dr. Graciela Gonzalez-Hernandez, Dr. Philip Gehrman and Dr. Allan Pack), we are colecting data from Twitter in two separate experiments:

1. Tweets mentioning the terms "have insomnia" or "hate insomnia", to evaluate the performance of a simple supervised machine learning classifier identifying tweets mentioning these sleep complaints;

2. Geotagged tweets posted within the boundaries of the United States, to evaluate the geographic and circadian distribution of tweets mentioning sleep complaints (using the model above), as well as the effect of the transition between daylight savings time and standard time on the these distributions.

This study is interdisciplinary becuase it uses concepts from sleep medicine, circadian biology, epidemiology and biomedical informatics. The sucessful completion of this study might reveal which regions of the United States are more likely to report sleep complaints in a social media platform. We hypothesize that there will be an effect of the latitude and distance from timezone boundaries on the prevalence of sleep complaints.
 
#### Methods

Data is currently being collected in parallel for experiments 1 and 2. Data from experiment 1 is being collected by Dr. Graciela Gonzalez-Hernandez using her team's scripts. Data for experiment 2 is being collected using the `rtweet` package. Data collection started on 10/30/2019 and will end after two weeks, on 11/13/2019. The transition from daylight savings time to standard time happened on 11/03/2016. Data is being collected using the following code:

```{r eval=FALSE}
## Load packages
library(rtweet)

## store api keys - these are kept blank here for security purposes
api_key <- ""
api_secret_key <- ""
access_token <- ""
access_token_secret <- ""

## authenticate via web browser
token <- create_token(
        app = "sleep_tweet_mazzottidr",
        consumer_key = api_key,
        consumer_secret = api_secret_key,
        access_token = access_token,
        access_secret = access_token_secret)

t <- gsub(" ", "", gsub(":", "", gsub("-", "", Sys.time())))

fname <- paste0("USA_tweets_", t, ".json")

# Stream tweets in the USA for 2 weeks
stream_tweets(lookup_coords("usa"), timeout = 60*60*24*14, parse = F, gzip=T, language = "en", file_name = fname)

```

Additional methods will be available upon completion of data collection.


#### Results

Results will be available upon completion of data collection.